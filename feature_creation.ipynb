{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xapian\n",
    "\n",
    "dbpath = 'xapIndex_SenID_Text'\n",
    "datapath = 'wiki-pages-text/'\n",
    "\n",
    "TOP_RESULTS_LIMIT = 15\n",
    "def search(dbpath, querystring, offset=0, pagesize=10):\n",
    "    \n",
    "    database = xapian.Database(dbpath)\n",
    "    enquire = xapian.Enquire(database)\n",
    "    query_string = querystring\n",
    "\n",
    "    qp = xapian.QueryParser()\n",
    "    stemmer = xapian.Stem(\"english\")\n",
    "    qp.set_stemmer(stemmer)\n",
    "    qp.set_database(database)\n",
    "    \n",
    "    qp.set_stemming_strategy(xapian.QueryParser.STEM_SOME)\n",
    "    query = qp.parse_query(query_string)\n",
    "    #print \"Parsed query is: %s\" % str(query)\n",
    "\n",
    "    # Find the top results for the query.\n",
    "    enquire.set_query(query)\n",
    "    matches = enquire.get_mset(0, TOP_RESULTS_LIMIT)\n",
    "\n",
    "    # Display the results.\n",
    "    #print(%i results found.\" % matches.get_matches_estimated()\n",
    "    #print \"Results 1-%i:\" % matches.size()\n",
    "    \n",
    "    text_dictionary = {}\n",
    "    for m in matches:\n",
    "#         print('RANK:', m.rank + 1)\n",
    "#         print('PERCENTAGE MATCH:', m.percent)\n",
    "#         print('DOC ID:', m.docid)\n",
    "#         print('DOC TXT:', m.document.get_data())\n",
    "        decoded_text = m.document.get_data().decode('utf-8')\n",
    "        text_dictionary[(decoded_text.split(\",,,\")[1],decoded_text.split(\",,,\")[2])] =decoded_text.split(\",,,\")[0]\n",
    "                                                                                  \n",
    "\n",
    "    return text_dictionary\n",
    "\n",
    "\n",
    "query = \"When in rome do as romans do\"\n",
    "matches = search(dbpath, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "query_list = [query]*TOP_RESULTS_LIMIT\n",
    "feature_db = pd.DataFrame({\"claim\": query_list,\"evidence\":tuple(matches.keys())})\n",
    "#nltk.download('punkt')\n",
    "import nltk\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "def jaccard_coefficient(claim,evidence_list):\n",
    "    final_claims = []\n",
    "    final_evidences = []\n",
    "    claim_tokens = nltk.word_tokenize(claim[0])\n",
    "    for claims in claim_tokens:\n",
    "        stemmed_lowercased_claim = stemmer.stem(claims.lower())\n",
    "        final_claims.append(stemmed_lowercased_claim)\n",
    "    #print(final_claims)\n",
    "    \n",
    "    #print(set(claim[0].split()))\n",
    "    #print(list(set(claim)))\n",
    "    #print((\"\".join(evidence_list).split()))\n",
    "    evidence_tokens = nltk.word_tokenize(\"\".join(evidence_list))\n",
    "    for evidence in evidence_tokens:\n",
    "        stemmed_lowercased_evidence = stemmer.stem(evidence.lower())\n",
    "        final_evidences.append(stemmed_lowercased_evidence)\n",
    "    #print(final_evidences)\n",
    "    #print([\"\".join(evidence_list).split()])\n",
    "    intersection = len(list(set(final_claims).intersection(set(final_evidences))))\n",
    "    #print(intersection)\n",
    "    union = (len(claim) + len(evidence_list)) - intersection\n",
    "    lower = min(len(final_claims),len(final_evidences))\n",
    "    jacc_LCS = []\n",
    "    jacc_LCS.append((1 - float(intersection / union)))\n",
    "    jacc_LCS.append(float(intersection/lower))\n",
    "    return jacc_LCS\n",
    "\n",
    "\n",
    "# def Longest_Common_Subsequence(claim,evidence_list):\n",
    "#     final_claims = []\n",
    "#     final_evidences = []\n",
    "#     claim_tokens = nltk.word_tokenize(claim[0])\n",
    "#     for claims in claim_tokens:\n",
    "#         stemmed_lowercased_claim = stemmer.stem(claims.lower())\n",
    "#         final_claims.append(stemmed_lowercased_claim)\n",
    "#     evidence_tokens = nltk.word_tokenize(\"\".join(evidence_list))\n",
    "#     for evidence in evidence_tokens:\n",
    "#         stemmed_lowercased_evidence = stemmer.stem(evidence.lower())\n",
    "#         final_evidences.append(stemmed_lowercased_evidence)\n",
    "#     intersection = len(list(set(final_claims).intersection(set(final_evidences))))\n",
    "#     lower = min(len(final_claims),len(final_evidences))\n",
    "#     return float(intersection/lower)\n",
    "\n",
    "def noun_count(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    count = 0\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\" or token.pos_ == \"NOUN\":\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>compare_length</th>\n",
       "      <th>LCS</th>\n",
       "      <th>Noun_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(When_in_Rome, 3)</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(When_in_Rome,_do_as_the_Romans_do, 6)</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(When_in_Rome,_do_as_the_Romans_do, 0)</td>\n",
       "      <td>0.979522</td>\n",
       "      <td>0.947183</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(When_in_Rome_Do_as_The_Vandals, 0)</td>\n",
       "      <td>0.983287</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(Greta_Rana, 11)</td>\n",
       "      <td>0.977860</td>\n",
       "      <td>0.942748</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(Peace_thru_Vandalism, 3)</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(Anapodoton, 5)</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(When_in_Rome,_do_as_the_Romans_do, 5)</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(Roman_Party, 1)</td>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.942966</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(No_Apologies_-LRB-The_Eyeliners_album-RRB-, 1)</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(Hocus_Pocus_-LRB-song-RRB-, 11)</td>\n",
       "      <td>0.961832</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(Peace_Thru_Vandalism_/_When_in_Rome_Do_as_The...</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.887218</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(Sin_of_omission, 11)</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(Peace_thru_Vandalism, 2)</td>\n",
       "      <td>0.966216</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>When in rome do as romans do</td>\n",
       "      <td>(Pseudo-Zacharias_Rhetor, 11)</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           claim  \\\n",
       "0   When in rome do as romans do   \n",
       "1   When in rome do as romans do   \n",
       "2   When in rome do as romans do   \n",
       "3   When in rome do as romans do   \n",
       "4   When in rome do as romans do   \n",
       "5   When in rome do as romans do   \n",
       "6   When in rome do as romans do   \n",
       "7   When in rome do as romans do   \n",
       "8   When in rome do as romans do   \n",
       "9   When in rome do as romans do   \n",
       "10  When in rome do as romans do   \n",
       "11  When in rome do as romans do   \n",
       "12  When in rome do as romans do   \n",
       "13  When in rome do as romans do   \n",
       "14  When in rome do as romans do   \n",
       "\n",
       "                                             evidence  jaccard_similarity  \\\n",
       "0                                   (When_in_Rome, 3)            0.929412   \n",
       "1              (When_in_Rome,_do_as_the_Romans_do, 6)            0.942308   \n",
       "2              (When_in_Rome,_do_as_the_Romans_do, 0)            0.979522   \n",
       "3                 (When_in_Rome_Do_as_The_Vandals, 0)            0.983287   \n",
       "4                                    (Greta_Rana, 11)            0.977860   \n",
       "5                           (Peace_thru_Vandalism, 3)            0.945055   \n",
       "6                                     (Anapodoton, 5)            0.972603   \n",
       "7              (When_in_Rome,_do_as_the_Romans_do, 5)            0.974359   \n",
       "8                                    (Roman_Party, 1)            0.977941   \n",
       "9     (No_Apologies_-LRB-The_Eyeliners_album-RRB-, 1)            0.973684   \n",
       "10                   (Hocus_Pocus_-LRB-song-RRB-, 11)            0.961832   \n",
       "11  (Peace_Thru_Vandalism_/_When_in_Rome_Do_as_The...            0.965035   \n",
       "12                              (Sin_of_omission, 11)            0.977778   \n",
       "13                          (Peace_thru_Vandalism, 2)            0.966216   \n",
       "14                      (Pseudo-Zacharias_Rhetor, 11)            0.978261   \n",
       "\n",
       "    compare_length       LCS  Noun_ratio  \n",
       "0         0.802632  0.857143    0.666667  \n",
       "1         0.842105  0.857143    0.500000  \n",
       "2         0.947183  0.857143    0.166667  \n",
       "3         0.957143  0.857143    0.086957  \n",
       "4         0.942748  0.857143    0.181818  \n",
       "5         0.814815  0.714286    0.285714  \n",
       "6         0.928571  0.857143    0.285714  \n",
       "7         0.896552  0.571429    0.285714  \n",
       "8         0.942966  0.857143    0.200000  \n",
       "9         0.893617  0.571429    0.200000  \n",
       "10        0.876033  0.714286    0.333333  \n",
       "11        0.887218  0.714286    0.166667  \n",
       "12        0.878049  0.428571    0.333333  \n",
       "13        0.891304  0.714286    0.222222  \n",
       "14        0.880952  0.428571    0.222222  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#def create_features(feature_db):\n",
    "feature_db['jaccard_similarity'] = [(jaccard_coefficient(feature_db['claim'],evidence))[0] for evidence in matches.values()]\n",
    "feature_db['compare_length'] = [(len(evidence) - len(feature_db['claim']))/len(evidence) for evidence in matches.values()]\n",
    "feature_db['LCS'] = [(jaccard_coefficient(feature_db['claim'],evidence))[1] for evidence in matches.values()]\n",
    "feature_db['Noun_ratio'] = [noun_count(feature_db['claim'][0])/noun_count(evidence) for evidence in matches.values()]\n",
    "#return feature_db\n",
    "feature_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_list = [query]*TOP_RESULTS_LIMIT\n",
    "# dataset = pd.DataFrame({\"claim\": query_list,\"evidence\":tuple(matches.keys())})\n",
    "\n",
    "#create_features(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16079</th>\n",
       "      <td>Solanum contains plants with ornamental flowers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114789</th>\n",
       "      <td>A Good Day to Die Hard is part of the Library ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126871</th>\n",
       "      <td>The Icelandic Coast Guard is also known as Gae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226458</th>\n",
       "      <td>Chadwick Boseman portrayed a film character.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132649</th>\n",
       "      <td>Ghost is a film.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51263</th>\n",
       "      <td>James Brolin is an orthodontist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51262</th>\n",
       "      <td>Superhuman abilities may result from antelope ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51260</th>\n",
       "      <td>Robinson Crusoe on Mars was a Greek tragedy.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    claim\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "16079    Solanum contains plants with ornamental flowers.\n",
       "114789  A Good Day to Die Hard is part of the Library ...\n",
       "126871  The Icelandic Coast Guard is also known as Gae...\n",
       "226458       Chadwick Boseman portrayed a film character.\n",
       "132649                                   Ghost is a film.\n",
       "51263                    James Brolin is an orthodontist.\n",
       "51262   Superhuman abilities may result from antelope ...\n",
       "51260        Robinson Crusoe on Mars was a Greek tragedy."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = pd.read_json('test-unlabelled.json',orient=\"index\")\n",
    "data.head(10)\n",
    "\n",
    "#create_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14997"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>Raven-Symoné is an Anglican.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>Temple of the Dog celebrated the 37th annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223218</th>\n",
       "      <td>FC Bayern Munich was sponsored by Pepsi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55615</th>\n",
       "      <td>Stomp the Yard stars an American actor born in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    claim\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "110000                       Raven-Symoné is an Anglican.\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "73397   Temple of the Dog celebrated the 37th annivers...\n",
       "...                                                   ...\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "223218           FC Bayern Munich was sponsored by Pepsi.\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "55615   Stomp the Yard stars an American actor born in...\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasubset = data.iloc[0:20]\n",
    "datasubset.loc[np.repeat(datasubset.index.values, TOP_RESULTS_LIMIT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:19<06:07, 19.36s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-32b69a721e28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdatasubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'evidence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_dictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/my_project_dir/my_project_env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3370\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_project_dir/my_project_env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3445\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3446\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_project_dir/my_project_env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3629\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3630\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3631\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_project_dir/my_project_env/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "#matches is iteratively changed\n",
    "from tqdm import tqdm\n",
    "match_dictionary = {}\n",
    "with tqdm(total=len(datasubset['claim'])) as pbar:\n",
    "    for index in range(0,len(datasubset['claim'])):\n",
    "        matches = search(dbpath, datasubset['claim'].iloc[index])\n",
    "        match_dictionary.update(matches)\n",
    "    #[matches = search(dbpath, data['claim'].iloc[index]) for index in range(len(data['claim']))]\n",
    "    pbar.update(1)\n",
    "    \n",
    "\n",
    "datasubset['evidence'] = tuple(match_dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
