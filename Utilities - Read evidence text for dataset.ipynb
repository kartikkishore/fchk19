{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "devsetPath = 'data/devset.json'\n",
    "datapath = 'data/wiki-pages-text/'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filesInDataPath = sorted([datapath + fileName for fileName in os.listdir(datapath)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "devset = pd.read_json(devsetPath, orient='index')\n",
    "devset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvidenceText(vocab, listofLists):\n",
    "    if len(listofLists) > 0:\n",
    "        evidenceText = []\n",
    "        for subList in listofLists:\n",
    "            searchString = subList[0] + ' ' + str(subList[1])\n",
    "            try:\n",
    "                evidenceText.append(vocab[searchString])\n",
    "            except KeyError:\n",
    "                searchString = normalize(searchString)\n",
    "                evidenceText.append(vocab[searchString])\n",
    "        return evidenceText\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "finalDF = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def shardToDF(shardPath):\n",
    "    tempArray = []\n",
    "    with open(shardPath, 'r') as openedFile:\n",
    "        for line in openedFile:\n",
    "            pageTitle, sentenceNo, pageText = line.split(' ', 2)\n",
    "            try:\n",
    "                sentenceNo = int(sentenceNo)\n",
    "            except Exception:\n",
    "                pass\n",
    "            tempArray.append([pageTitle, sentenceNo, pageText])\n",
    "        tempDF = pd.DataFrame.from_records(tempArray, columns=['pageTitle','sentenceNo' ,'pageText'])\n",
    "        tempDF = tempDF.groupby(\"pageTitle\").aggregate(list).reset_index()\n",
    "        return tempDF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tqdm(total=len(filesInDataPath)) as pbar:\n",
    "    for path in filesInDataPath:\n",
    "        finalDF = pd.concat((finalDF, shardToDF(path)))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "finalDF['data'] = finalDF.swifter.apply(lambda x: dict(zip(x['sentenceNo'], x['pageText'])), axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "finalDF.to_pickle('data/lookupDataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get page text from the data loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = pd.read_pickle('data/lookupDataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes about 2-3 minutes, big file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPageText(pageTitle):\n",
    "    return list(finalDF[finalDF['pageTitle'] == pageTitle]['data'].values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Damon Albarn , OBE -LRB- -LSB- ˈdeɪmən_ˈælbɑrn -RSB- born 23 March 1968 -RRB- is an English musician , singer , songwriter , multi-instrumentalist and record producer .\\n',\n",
       " 1: 'He is the lead singer of the British rock band Blur and co-founder , vocalist , instrumentalist and principal songwriter of the virtual band Gorillaz .\\n',\n",
       " 4: 'Raised in Leytonstone , East London and around Colchester , Essex , Albarn attended the Stanway School , where he met Graham Coxon and eventually formed Blur , whose debut album Leisure was released in 1991 to mixed reviews .\\n',\n",
       " 5: \"After spending long periods of time touring the US , Albarn 's songwriting became increasingly influenced by British bands from the 1960s .\\n\",\n",
       " 6: 'The result of these influences came in the form of Modern Life Is Rubbish -LRB- 1993 -RRB- , Parklife -LRB- 1994 -RRB- and The Great Escape -LRB- 1995 -RRB- .\\n',\n",
       " 7: 'All three albums received critical acclaim while Blur gained mass popularity in the UK , aided by a Britpop rivalry with Oasis .\\n',\n",
       " 8: 'Subsequent albums such as Blur -LRB- 1997 -RRB- , 13 -LRB- 1999 -RRB- , Think Tank -LRB- 2003 -RRB- and The Magic Whip -LRB- 2015 -RRB- contained influences from lo-fi , electronic and hip hop music .\\n',\n",
       " 11: \"Along with Tank Girl creator Jamie Hewlett , Albarn formed the `` virtual band '' Gorillaz in 1998 .\\n\",\n",
       " 12: 'Drawing influences from alternative rock , trip hop , hip hop , electronica , dub , reggae and pop music , the band released their self-titled debut album in 2001 to worldwide success .\\n',\n",
       " 13: 'Although Albarn is the only permanent musical contributor , the albums feature collaborations from a wide range of artists .\\n',\n",
       " 14: \"Gorillaz are cited by the Guinness Book of World Records as the `` Most Successful Virtual Band '' .\\n\",\n",
       " 15: 'Other projects include working with African musicians in aid of the charity Oxfam , writing and performing lead vocals on The Good , the Bad & the Queen as part of an unnamed supergroup and composing film soundtracks .\\n',\n",
       " 16: 'He has also ventured into the world of opera with Dr Dee and Monkey : Journey to the West .\\n',\n",
       " 17: 'His debut solo studio album Everyday Robots -- co-produced by XL Recordings CEO Richard Russell -- was released on 28 April 2014 and featured collaborations with Brian Eno , Natasha Khan and the Leytonstone City Pentecostal Mission Church Choir as well as sampling several rants by Lord Buckley .\\n',\n",
       " 20: \"In 2008 , The Daily Telegraph ranked Albarn number 18 in their list of the `` 100 most powerful people in British culture '' .\\n\",\n",
       " 21: 'In a 2010 UK poll for Q magazine Albarn was voted the fourth-greatest frontman of all time .\\n',\n",
       " 22: 'He was appointed Officer of the Order of the British Empire -LRB- OBE -RRB- in the 2016 New Year Honours for services to music .\\n'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPageText('Damon_Albarn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = loadVocab(filesInDataPath)\n",
    "devset['evidence_text'] = devset['evidence'].apply(lambda x: getEvidenceText(vocab, x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
